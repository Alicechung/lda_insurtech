Big Data, Value-Based Reimbursement Must Combine for Quality

July 21, 2015

By Jennifer Bresnick
July 21, 2015 - The healthcare industry has faced any number of significant challenges during its rapid transition from paper to electronic health records, not least of which is defining the differences between “data” and “information.”  In healthcare’s new big data world, patient records may be stuffed full of results, statistics, notes, and codes that convey no clear, immediate meaning to a treating physician, producing frustration instead of illumination when it comes to what the patient really requires. 
While it is certainly important to engineer a healthcare system that enables providers to quickly and efficiently access the maximum amount of data on a patient to support informed decision making, providers and regulators are still struggling to quantify how big data brings measurable value to the care continuum.
This is an especially important question to answer as public and private payers begin to embrace value-based reimbursement, which focuses on delivering quality instead of quantity in an effort to rein in rampant spending.  But what exactly does “quality” mean?  Who determines when a provider has achieved a sufficient level of “value” in their care?
These are issues that the National Quality Forum (NQF) has tried to address by endorsing metrics and developing guidelines to create a standardized framework for judging the quality of care.  But the process hasn’t been an easy one. 
As NQF President and CEO Christine Cassel, MD, discussed in the first part of her interview with HealthITAnalytics.com, healthcare big data analytics is as filled with potential as it is problematic.  Health IT systems suffer from any number of image problems, including poor usability, disappointing data integrity, siloed information, and conflicting standards, stymying progress towards an interoperable, data-driven, learning health system that embraces big data as its guiding spark for quality improvements.
READ MORE: CIOs Focus on EHR Optimization for Population Health, Analytics
With the January announcement that 50 percent of Medicare payments will be tied to pay-for-performance programs by 2018, HHS has made the big data conundrum a top priority for healthcare organizations that wish to set themselves up for success in a world where big data and meaningful value-based reimbursement work together.  Private payers have also been eager to make accountable care a way of life for their providers, but how can healthcare organizations navigate this difficult transition?
“Providers are starting to understand that healthcare is now going to be about organizing a system around the patient, and having all of that information at your fingertips in order to make sure that patient gets what they need and not what they don’t need,” Cassel said.  “That’s what we mean by personalized care.  If a payment system doesn’t support that, then it becomes very hard to achieve that balance.  When providers are confused about whether they’re being paid for volume or being paid for value, it makes it very hard to organize an efficient approach to designing a system of care.”
“First, you must make sure that consumers can be confident that providers aren’t stinting on care,” she continued.  “That’s one of the concerns about some of these models, and consumers are nervous.    Is my provider going to be withholding something that I might need because they won’t get paid for it?  Am I going to suffer from that?  I think the culture around that is changing now, and patients are starting to understand that more is not always better, but we need to continue to pay attention to those concerns.”
It’s hard enough to change an industry’s attitudes towards its primary purpose, and harder still to measure that shift as it is happening.  But quality metrics are critically important for the success of value-based reimbursement, Cassel says.
“If you’re going to pay for value, you must have a way to know value when you see it,” she explains.  “To do that, you have to have really good measures of value.  We consider value to be the product when you add cost of care plus quality of care.  That means you always need to report those two things together, and the NQF has been doing a lot of work in this area to try to figure out the most efficient method for doing this.”
READ MORE: Blockchain Will “Change the Physics” of Health Data Sharing
To fully measure quality, providers must have complete understanding a patient’s journey across the care continuum, and how each provider’s actions affect the decisions of the rest.  Are primary care providers collaborating with specialists?  Are hospitals sending admissions and discharge notifications to their partners?  Is chronic disease management being handled effectively, or are patients slipping through gaps in care coordination or access?  Big data can answer these questions, but health IT systems need to be able to aggregate and present the necessary information, which has historically been one of the industry’s greatest challenges.
Health data interoperability is not at the level that it should be in order to support advanced quality measurement and big data analytics initiatives, despite intense focus from industry stakeholders and regulators alike.  The ONC recently released a ten-year roadmap to interoperability that is intended to guide the industry as it makes connections and develops networks for health information exchange, but the decade-long vision may not be adequate.
“I have said to my friends and colleagues at ONC that I actually think that the 10-year interoperability framework needs to go faster,” said Cassel.  “I don’t think we have ten years to wait for interoperability.  And frankly I think the innovation environment is moving very rapidly, and the answers are out there.  There are so many really, really smart innovators who are figuring out how to create interoperability where it doesn’t exist now, to create a home for the patient’s voice, and to increase access to patient data in a way that consumers can really use.”
“So, I actually think that, if you look at how rapidly the world is changing, I think in three to five years we’re going to have a very, very different landscape about health information,” she predicts.  “We just need to be very open to new ways of thinking and new opportunities.”
Healthcare organizations will need to embrace cultural changes, not just technological ones, added NQF Senior Director Robert Saunders, PhD.  “One of the things we’ve been hearing, and that’s worth underscoring, is that there are so many real-world challenges with interoperability that go deeper than the technology,” Saunders said. 
READ MORE: What Does “Pick Your Own Pace” MACRA Mean for Data Analytics?
“We don’t just focus on getting providers to trust the data, or getting the consumer to trust the provider. We have to solve a lot of the systemic challenges that make it so difficult to achieve interoperability.  That’s part of our scope and the goals that we have.  We need to start identifying some strategies for overcoming those obstacles.”
“To do that, we have to make sure that clinicians and the physician community – from surgeons and internal medicine practitioners to other specialties and nurse practitioners and other providers – are involved in our committees and that they are providing that sort of frontline experience and real world experience of what’s working well.  They know where the challenges are, and they know where the gaps are.  They know where we’re not meeting their goals, or when they’re not getting the information they wish they could get.  It’s so important to hear their feedback and take their concerns into account if we’re going to make progress.”
Physicians and front-line staff have never been shy about offering feedback.  Clinicians have long complained that health IT makes their jobs more difficult rather than the other way around.  While usability issues are a very valid concern, that distrust and frustration may also stem from a fundamental misunderstanding of the role of technology in the healthcare system.  EHRs cannot, and arguably should not, simply mimic paper processes that worked well enough once upon a time.   Health IT is capable of so much more – if providers can adapt their expectations and experiences to make the most of the tools they are given.
“We absolutely need better data and easier access to data, but we also need the analytic skills to make sense of it,” Cassel argues.  “Once you have data that you trust, you have to understand something about the system’s science of improvement.  Quality improvement itself is a science that is somewhat separate from the science of patient care.”
“Not all physicians really think about it that way,” she added.  “They think, ‘I just need to stay at work longer, and work harder, and check everything three times.’  In fact, sometimes that’s not the best approach.  There are more efficient ways to achieve quality improvements.   We have heard that providers need more access to resources to teach them about improvement science.  That should be one of the core skills, really, for healthcare providers going forward.”
Nurses with a flair for informatics and health information management professionals have always been extraordinarily active leaders in the quality and process improvement sphere, but physicians are joining in, too.  The American Board of Medical Specialties approved clinical informatics as a valid subspecialty in 2011, and the first physicians passed their exams at the end of 2013.  Physicians are common players in the vendor community, leading usability teams or designing new health IT systems to solve pressing problems in clinical practice, and there’s no shortage of interest among healthcare professionals of all backgrounds in how to make technology work smarter, faster, and better at the bedside.
“When it comes to identifying physician leaders, there are exemplars that are scattered throughout our system, no matter what size practice or health system they are working with,” agrees Dr. Prabhjot Singh, Special Advisor for Strategy and Design at the Peterson Center for Healthcare.  “We need to work on our abilities to identify emergent leadership, to foster it and amplify it, in order to bring improvements to the system in a meaningful, practical way.”
“The Peterson Center on Healthcare is particularly focused on the way that will happen at the practice level, and how we can help both consumers and practitioners solve that problem,” he continued.  “We are keenly following the work and guidance of colleagues that are working on the policy side, because we know that it is very important to do the policy-level work on facilitating the environment that we need for practitioners to be able to actually utilize their big data.”
“We feel confident that there's a lot of good work being done in that area.  It’s a very good sign that people are starting to ask what they need to do to systematically accelerate performance in a way that improves quality and improves affordability for the entire healthcare system.”
Tagged Accountable CareAnalytics InfrastructureBig Data AnalyticsInteroperabilityQuality Of Care


