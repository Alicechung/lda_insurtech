Leveraging the clinical data warehouse for accountable care

October 08, 2014

By Sponsored Content
October 08, 2014 - Throughout this series, we explored how to create an integrated data asset through the integration of claims, clinical, financial and other data sources; how data from those sources is extracted; and how it’s organized between patient records in disparate systems.
Once these elements are in place, the next step is to take a look at how this data is stored to allow for flexibility and transparency. In other words, what can your data warehouse tell you?
As quality and utilization reporting becomes a critical piece of contracts between health systems and health plans, many have only the basic ability to analyze a subset of measures.  To really drive improvement, systems need a broad and unified dataset with three advanced capabilities: a longitudinal population view, the ability to forecast contract performance and an overall means to foster trust and confidence in the data.
The longitudinal patient/population view
As noted above, most organizations have the basic ability to provide a snapshot of their performance at a particular point in time. Add enough of these data points together and the resulting trend starts to show the bigger picture for performance, including opportunities for improvement. However, a true longitudinal view requires the ability to highlight and identify long-term patterns and trends. Take a look at the graph below that shows a snapshot of the year in the life of a patient:
READ MORE: Roche Buys Flatiron Cancer Analytics, EHR Tools for $1.9B
  The data warehouse provides a rich contextualized view of a patient’s care throughout the year. Each colored square represents a week in the patient record, showing activity from a range of care settings, both inpatient and outpatient, including tests ordered, screenings and other treatments surrounding both the two early outpatient appointments and throughout the two-week, mid-summer hospital stay.
  There is more here than utilization and expense. We can see, for instance, when a provider and patient are communicating via the patient portal. We can also see how the documentation of vitals (for example, blood pressure) becomes more frequent post-discharge, while the patient is on more medications.
READ MORE: 84% of Execs: Artificial Intelligence Will Transform Healthcare
Could these data points been used to help predict or interdict the hospital stay this patient incurred in July and August? Maybe, maybe not, but a rich contextualized view for each patient creates a clear, verifiable chain of clinical documentation, claims expenses and episodes – all of which lead up to aggregate performance improvement and population health measurement.
Show value: Forecast the consequence of value-based contracts
Whether entering an accountable care organization, a bundled payment program, or a pay-for-performance incentivized contract, each model has certain quality standards that must be reported on and monitored. While many applications can produce a time-series presentation of measure performance, the basic analysis of trends, which are the key to communicating the importance of measure performance, lies in the ability to directly tie the measure to financial outcomes.
In other words, what can be earned by moving the measure 1% higher? Combine this insight with staff performance incentives and it has the potential to vastly improve performance communication.
A key capability of advanced analytics architectures is the ability to show that every measure consists of both patients that meet the measure, as well as the gaps that missed it.
READ MORE: GE, Roche Partner for Big Data Analytics, Precision Medicine Platform
In some cases, screening one more patient makes the difference between hitting a contracted milestone and missing it. The analytics system needs not only a longitudinal awareness (as mentioned above), but also the flexibility to weigh who hits a milestone and who misses it. This allows for accurate and on-going simulation of contracted performance.
Where did that come from? Trust and transparency
Throughout this series on analytics, we have shown the importance of data sources and methodical processes for the merger of data points  in a common platform. The result is a great, longitudinal view of the patient, and a unique ability to forecast performance in an actionable way. However, the last and most important capability necessary to create a real data asset is trust. If a data warehouse can’t be relied on to identify the source of every data point being warehoused, than it can’t be fully tested or audited, which results in a loss of trust.
While each of the components, such as the ETL connector process and the Master Patient Index, have their own independent monitoring and validation processes, the final data warehouse, which powers the resulting analytics intelligence, needs to have an auditable calculation trail that leads from the aggregate score and pinpoints specific dates for  patient events, including dates and codes, documented by staff directly  to the EHR. If these events are documented in the warehouse, it must be audited as if that database record is a signed-note. This means that for every prescription, problem list entry, claim, CPT code, blood pressure reading, etc., the following traceable information is maintained:
• Source Identifier:  The key identifier of the element that that has been extracted such as an e-prescription or other type of database key for the record from the source system.
• Encounter Identifier: A link to the encounter or claim under which this element was documented or billed.
• Users Identifier: The username (in source system) and times that the updated record was modified in the source system.
• Rendering Provider: If the record was created by someone other than the user identified by the user name, the rendering provider (who signs off on the encounter) must also be present.
Merely possessing an auditable dataset isn’t enough, however. Users need access to it. While a web reporting platform is essential for administrative or clinical staff that need certain reliable capabilities, nothing beats direct, “back-end” access to the underlying database for answering complex questions. This means creating an interface for back-end access to the underlying database, as well as creating a comprehensible data model and providing clients with documentation for its use. By providing back-end access to a well-ordered and effective data model, users of the system can run their own analysis, monitor their calculation processing and gain more usage of the data warehouse, inspiring trust through verification.
Finally, not only must all of this auditable information be stored and accessible to users, but this data must also be able explain how the results for specific measures are determined.
Traditionally, each measure consists of four components: initial patient population, denominator, numerator and exclusion elements. The data element calculation that would cause a patient to hit any of these components is directly linked. A skeptical provider viewing their performance for the first time may ask, “why was this patient counted?” He or she should expect to be able to see the encounters, documented lab tests, or claims that led to that determination. This is an essential capability for the successful integration of analytics architecture. .
In the next post, we will look into how to navigate the complexity of building measures in an analytics platform.
  Tagged Analytics InfrastructureBig DataClinical Analytics


