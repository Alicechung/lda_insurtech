Inspur Demonstrates The Latest AI Computing Platform At Gartner Catalyst Conference 2017

22 Aug 2017

Inspur, a leading datacenter and cloud computing total solutions provider is showcasing its newest Intel Xeon Scalable Processor family products supporting the next generation datacenter, cloud infrastructure and AI platforms at Gartner Catalyst Conference 2017 on August 21-24, San Diego, California. Dolly Wu, VP and GM of Inspur Cloud Datacenter USA Division, and Alfie Lew, Solutions Architect, will have a speaking session (August 22nd, 10:10am~10:55am, Grand Hyatt Seaport Ballroom D) to share with the event attendees “How to design large-scale AI and Deep Learning platforms, from data pre-processing to training and inferencing.”
Built on Gartner, the world’s leading information technology research and advisory company, Gartner Catalyst Cloud and IoT Conference attracts many CTOs, engineers, scientists, scientists and researchers, and authoritative analysts every year. Artificial Intelligence is the primary focus of this event in 2017. Gartner believes within 10 years, AI will become the most disruptive technology, pushing forward by technological advancements in computing, data collection and deep neural networks.
“Innovations in computing drive strong momentums for AI development. Inspur is committed to providing her users with exclusive AI computing platforms and is the only manufacturer with the capability to provide a complete set of turnkey solutions for AI. Inspur is an important partner and supplier for world-leading CSPs including Baidu, Tencent, and Alibaba. Our AI platforms are widely adopted for driverless car technologies, image searching and voice recognition, accounting for over 60% of the AI market share in China,” said Dolly Wu, VP and GM of Inspur Cloud Datacenter Division in USA.
Inspur is demonstrating three newly released AI computing platforms at the event. On display will be the Inspur AGX-2, the world’s highest density AI Supercomputer, supporting 8 *NVIDIA® Volta® 100 GPUs with NVLink 2.0 enabled in a 2U form factor. The network bandwidth between GPUs can reach 150GB/s. This product boasts ideal linear extension: When using TensorFlow framework and GoogleNet model testing, the 8*GPUs configuration can process 1165 images per second, which is 2.49 times that of 4*GPUs. Another product is the Inspur SR-AI Rack, which can pool the physical decoupling of GPU and CPU with each node supporting maximum 16 pieces of GPUs and each system 64 pieces of GPUs. Its peak capacity can reach 512TFlops. This solution is supporting scale applications in Baidu’s AI business.
Inspur also provides end-to-end solutions for AI applications, covering AI hardware, frameworks, managing tools and optimizing tools as well as assisting customers in transferring applications. Inspur created the Caffe-MPI framework, based on the mainstream AI framework Caffe. In May 2017, Inspur released the AI training cluster management software, AIStation, which provides the complete business process of preparing data to analyzing training results and supporting various computing frameworks such as Caffe, TensorFlow, CNTK and various models such as GoogleNet, VGG, ResNet. The Inspur AIStation has an unified management system for different models and training tasks; it documents and analyzes loss functions and training errors during the training process, enabling users to identify the root cause of problems in AI models during training, not after the training.
Dolly said, “In addition to developing various platforms and computing tools, Inspur is also developing an AI industrial ecosystem. Inspur and Intel jointly developed FPGA, KNL and relevant products. Together with NVIDIA, Inspur is co-developing AI computing innovative products based on GPU. Inspur fosters close partnerships with many top Internet companies and integrates our computing platforms with AI algorithm and software applications to deliver end-to-end solutions to support and promote the rapid growth of AI adoption in more and more industries and use cases.”


